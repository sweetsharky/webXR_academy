<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Image target with glb (only Android)</title>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=no"
    />
    <link type="text/css" rel="stylesheet" href="style.css" />
    <script
      src="https://unpkg.com/three@0.133.0/build/three.js"
      crossorigin="anonymous"
    ></script>
    <script src="https://unpkg.com/three@0.133.0/examples/js/loaders/GLTFLoader.js"></script>
    <script src="//cdn.jsdelivr.net/npm/eruda"></script>
  </head>

  <body>
    <div id="console-ui"></div>
    <script type="module">
      setupMobileDebug();
      // Unfortunately for now this example only works on Android phones and tablets!

      import { ARButton } from "https://unpkg.com/three@0.133.0/examples/jsm/webxr/ARButton.js";

      let camera, scene, renderer;
      let mesh;
      let image;
      let loader; // we need to create a variable for a glb model loader
      let model; // save reference to model

      init();
      animate();
      
      function setupMobileDebug() {
      // First thing we do is setup the mobile debug console
      // This library is very big so only use it while debugging
      // just comment it out when your app is done
        const containerEl = document.getElementById("console-ui");
        eruda.init({
          container: containerEl
        });
        const devToolEl = containerEl.shadowRoot.querySelector('.eruda-dev-tools');
        devToolEl.style.height = '40%'; // control the height of the dev tool panel
      }

      async function init() {
        const container = document.createElement("div");
        document.body.appendChild(container);

        scene = new THREE.Scene();

        camera = new THREE.PerspectiveCamera(
          70,
          window.innerWidth / window.innerHeight,
          0.01,
          40
        );

        renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.xr.enabled = true;
        container.appendChild(renderer.domElement);

        const light = new THREE.HemisphereLight(0xffffff, 0xbbbbff, 1);
        light.position.set(0.5, 1, 0.25);
        scene.add(light);

        await loadModel();

        // setup the image target
        const url =
          "https://cdn.glitch.global/0761b046-c0dd-4253-9564-a3c4b87d1542/cat.jpg?v=1642957357381";
        const imgBitmap = await getImageBitmap(url);

        const button = ARButton.createButton(renderer, {
          requiredFeatures: ["image-tracking"], // notice a new required feature
          trackedImages: [
            {
              image: imgBitmap, // tell webxr this is the image target we want to track
              widthInMeters: 0.7,
            },
          ],
          optionalFeatures: ["dom-overlay", "dom-overlay-for-handheld-ar"], // so we can see the debugging
          domOverlay: {
            root: document.body
          }
        });
        document.body.appendChild(button);

        window.addEventListener("resize", onWindowResize, false);
      }
      
      // add the model one time to the scene
      async function loadModel() {
        const modelUrl =
          "https://raw.githubusercontent.com/sweetsharky/media/refs/heads/main/s%C3%A4ge/s%C3%A4ge.gltf";

        const loader = new THREE.GLTFLoader();
        
        const gltf = await loader.loadAsync(modelUrl); 
        model = gltf.scene; // I'd suggest saving a reference to the model this way
        
        // model.matrixAutoUpdate = false;
        model.scale.multiplyScalar(20);
        model.visible = false; // start as invisible
        
        scene.add(model);
      }

      function onWindowResize() {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();

        renderer.setSize(window.innerWidth, window.innerHeight);
      }

      function animate() {
        renderer.setAnimationLoop(render);
      }

      async function getImageBitmap(url) {
        const response = await fetch(url);
        const blob = await response.blob();
        const imageBitmap = await createImageBitmap(blob);
        return imageBitmap;
      }

      // update the cone mesh when the image target is found
      // PENDING: have to fix model positioning
      function updateMesh(pose) {
        if (model) {
          model.rotation.x = pose.transform.orientation.x;
          model.rotation.y = pose.transform.orientation.y;
          model.rotation.z = pose.transform.orientation.z;
          
          model.position.x = pose.transform.position.x;
          model.position.y = pose.transform.position.y;
          model.position.z = pose.transform.position.z;
        }
      }

      function render(timestamp, frame) {
        if (frame) {
          const results = frame.getImageTrackingResults();

          for (const result of results) {
            // The result's index is the image's position in the trackedImages array specified at session creation
            const imageIndex = result.index;

            // Get the pose of the image relative to a reference space.
            const referenceSpace = renderer.xr.getReferenceSpace();
            const pose = frame.getPose(result.imageSpace, referenceSpace);

            const state = result.trackingState;

            if (state == "tracked") {
              // do something when image is tracked
              // console.log("Image target has been found");
              if (model) {
                model.visible = true;
                updateMesh(pose);
              }
            } else if (state == "emulated") {
              // do something when image is lost
              if (model) {
                model.visible = false;
              }
              // console.log("Image target no longer seen");
            }
          }
        }
        renderer.render(scene, camera);
      }
    </script>
  </body>
</html>
